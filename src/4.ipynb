{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39efb4d1",
   "metadata": {},
   "source": [
    "# 4. Data exploration\n",
    "\n",
    "So far, we've used scikit-learn correctly—building pipelines, applying GridSearchCV, and evaluating models properly.\n",
    "\n",
    "But from a data science perspective, we've skipped a critical step: exploring the data itself.\n",
    "We've treated the dataset as a black box without checking what features exist, what they mean, how they're distributed, or whether they make sense.\n",
    "This lack of exploratory data analysis (EDA) makes our modeling naive and potentially misleading.\n",
    "Before trusting any model output, we must understand the data we're working with—its structure, scale, quality, and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a01fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns a dictionary\n",
    "# print(load_boston())\n",
    "\n",
    "# One of the things in the dictionary is this description tag:\n",
    "print(load_boston()[\"DESCR\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565dc19",
   "metadata": {},
   "source": [
    "So now that we have looked at what we're actually dealing with. You can kind of wonder is 506 houses enough to give us a lot of confidence in our model? Maybe not. Also, what year is this from? Perhaps it is not reflective of the real world. That's also a valid concern.\n",
    "\n",
    "But it gets worse: now wehave things like crime in the neighbordhood, we have things like how industrious is the area, but the really bad thing is apparently the dataset has the proportion of blacks in your town (the `B` variable). This is something that really used to being used to predict a house price. Looking at this, we clearly have potential for a racist algorithm and we don't want this in production.\n",
    "\n",
    "So we have discussed methodology and so on but GridSearch is not enough and what's bothersome is that this dataset has been used for so long and in so many different courses *without even looking at the variables that are being put in a model*.\n",
    "\n",
    "This is also why scikit-learn has now described to remove this dataset!\n",
    "\n",
    "And this is the version why we had to pin the version of `scikit-learn` at the beginning, because `load_boston` is no longer available in future releases.\n",
    "\n",
    "Beyond technical correctness, this highlights a broader issue: machine learning can go very wrong when models are trained on biased or misunderstood data.\n",
    "In this project, we saw how models can appear to perform well—e.g., with optimistic scatter plots or rising GridSearchCV scores—while still being deeply flawed.\n",
    "Blind trust in these results can lead to harmful outcomes if models are deployed without scrutiny.\n",
    "To build reliable systems, it's your responsibility to:\n",
    " - Understand what is in your dataset.\n",
    "- Stay skeptical of model performance, especially when it's \"too good.\"\n",
    "- Consider ethical, social, and failure consequences of your models in production.\n",
    "\n",
    "Scikit-learn's API is powerful, but the hard part of data science is knowing when and how to use it responsibly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
