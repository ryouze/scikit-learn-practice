{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cfcbbf",
   "metadata": {},
   "source": [
    "# 6. Preprocessing part 2\n",
    "\n",
    "so far we've been doing a lot of pre-processing on numeric data\n",
    "\n",
    "but you can also imagine that we have data that's like this where maybe we have classes low medium high risk and then it will be nice if we can do some pre-processing such that this text data becomes numeric data as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725b1486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['low'],\n",
       "       ['low'],\n",
       "       ['high'],\n",
       "       ['medium']], dtype='<U6')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([\"low\", \"low\", \"high\", \"medium\"]).reshape(-1, 1)\n",
    "arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed7576",
   "metadata": {},
   "source": [
    "the most common technique for that is the one hot encoder\n",
    "\n",
    "now what this encoder will do is it will be able to take in an array of text or categories and transform that out to something that is indeed numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ef766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03428d",
   "metadata": {},
   "source": [
    " now if you just run this as is you're going to get a data structure that's known as a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4235db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit_transform(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89749f",
   "metadata": {},
   "source": [
    "there's a setting though that we can change such that the sparsity is false and then we can actually see what is inside of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dffc0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit_transform(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4da60",
   "metadata": {},
   "source": [
    "note that the first two rows are indicated as low and we can see that indeed they share the same column then we see high over here which is listed there and then we see medium below and that is listed there so we can see a form of correspondence and that is something that is indeed useful and the most common use case for this is if this is let's say the class that you would like to predict then this numeric representation that is going to be the y array that you're going to pass to psychic learn because this is something that psychic learn can use to train numerically on (`[0., 1., 0.],` -> `'low'`).\n",
    "\n",
    "there is some behavior to be aware of though and this is not super relevant if you're generating labels but it is relevant if you're using this onenote encoder to encode information for the data that will predict the label\n",
    "\n",
    "let's say i grab the encoder now and i ask it to transform something\n",
    "\n",
    "and what i'm asking it to transform is something that it's never seen before so notice that im asking it to give me a label for zero but zero does not appear in this set (np.array) and that is the set where we did perform a fit on so we might wonder what's going to happen here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a1405",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['zero'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/github-ryouze/scikit-learn-practice/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:428\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    426\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_idx_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/dev/github-ryouze/scikit-learn-practice/env/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:124\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    122\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i))\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Set the problematic rows to an acceptable value and\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# continue `The rows are marked `X_mask` and will be\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# removed later.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     X_mask[:, i] \u001b[38;5;241m=\u001b[39m valid_mask\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['zero'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "# enc.transform([[\"zero\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c78cfb",
   "metadata": {},
   "source": [
    "well we're going to get a big fat value error so it's saying value error found unknown category O.\n",
    "\n",
    "so essentially it is telling us you're not allowed to give me data that i've never seen before\n",
    "\n",
    "we can change the setting for this though because at the moment the handle unknown parameter is set to error but we can change that such that it's set to ignore\n",
    "\n",
    "and now if i run this it's not going to give me an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64cd76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "enc.fit_transform(arr)\n",
    "\n",
    "enc.transform([[\"zero\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af3206",
   "metadata": {},
   "source": [
    "and what it's doing is it's saying well these are all zeros or another way of saying that zero is neither low high or medium - so we can just go ahead and give it this zero array back\n",
    "\n",
    "now one thing to finally note about that is that this (`handle_unknown=\"ignore\"`) is a very useful setting if you're generating your x matrix so to say- but you don't want to do that if you're generating your y labels because those are things that you want to have very strict control over\n",
    "\n",
    "in this series of videos ive shown you some of the pre- processing steps that are available but a very convenient way for you to play around with more of them and to get a better understanding is to go to this website called drawdata.xyz - and full disclaimer it's a website that i made but it's a website that allows you to quite literally make a drawing of a little bit of data and that way you can play with it from your jupyter notebook and playing with preprocessors is the best way to learn about them now what you can go ahead and do from here once you've drawn your data set that you're interested in you can click this download csv button to download this file locally but what you can also do is you can copy the csv to your clipboard.\n",
    "\n",
    "what you can then do is you can type `pandas.read_clipboard()` and then this will be able to read from your clipboard the only thing you have to do manually is you gotta set the separator to a comma (`pd.read_clipboard(sep=\",\"`) because i think the clipboard is typically reading in from excel but what i can now do is just run this and lo and behold the data set that i was just drawing is now available to me here and this is a really nice way to just get a little bit playful with scikit-learn pre processing steps and pipelines\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
